{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "000bc9a4",
      "metadata": {},
      "source": [
        "# üîç GradFaith-CAM Demo Notebook\n",
        "\n",
        "**Seeing Isn‚Äôt Always Believing**  \n",
        "Grad-CAM Faithfulness & Localization Analysis  \n",
        "**KST 2026 | MARSAIL | Chulalongkorn University**\n",
        "\n",
        "---\n",
        "This notebook demonstrates:\n",
        "1. Model loading\n",
        "2. Grad-CAM generation\n",
        "3. Faithfulness evaluation\n",
        "4. Publication-quality visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13d6dc12",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "\n",
        "from gradcam.gradcam import GradCAM\n",
        "from gradcam.faithfulness import perturbation_faithfulness\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3555d00",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£ Load Pretrained Model\n",
        "We use **ResNet-50** as in the paper experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9732d21",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = models.resnet50(weights='IMAGENET1K_V2')\n",
        "model.eval().to(device)\n",
        "\n",
        "target_layer = model.layer4[-1]\n",
        "gradcam = GradCAM(model, target_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e54830ee",
      "metadata": {},
      "source": [
        "## 2Ô∏è‚É£ Load and Preprocess Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b47d6f0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "img_path = 'sample.jpg'  # replace with CT image\n",
        "img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "x = transform(img).unsqueeze(0).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bea79b9a",
      "metadata": {},
      "source": [
        "## 3Ô∏è‚É£ Prediction & Grad-CAM Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f6d0f12",
      "metadata": {},
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    logits = model(x)\n",
        "    pred_class = logits.argmax(1).item()\n",
        "\n",
        "cam = gradcam(x, pred_class).squeeze()\n",
        "\n",
        "print('Predicted class:', pred_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c854e8e0",
      "metadata": {},
      "source": [
        "## 4Ô∏è‚É£ Faithfulness Evaluation (Perturbation Test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e756f3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "faith = perturbation_faithfulness(model, x, cam, pred_class)\n",
        "print(f'Faithfulness score: {faith:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96cec187",
      "metadata": {},
      "source": [
        "## 5Ô∏è‚É£ Visualization (Publication Quality)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c78429ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "img_np = x.squeeze().permute(1,2,0).cpu().numpy()\n",
        "cam_np = cam.cpu().numpy()\n",
        "\n",
        "heatmap = cv2.applyColorMap((cam_np*255).astype(np.uint8), cv2.COLORMAP_JET)\n",
        "heatmap = heatmap[..., ::-1] / 255.0\n",
        "\n",
        "overlay = (0.5 * img_np + 0.5 * heatmap).clip(0,1)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(overlay)\n",
        "plt.title('Grad-CAM Explanation')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2130d10a",
      "metadata": {},
      "source": [
        "## ‚úÖ Key Takeaway\n",
        "- High-confidence predictions do **not guarantee faithful explanations**\n",
        "- GradFaith-CAM quantitatively exposes shortcut learning"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
